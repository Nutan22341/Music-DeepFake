{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11090464,"sourceType":"datasetVersion","datasetId":6913125}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/CodeVault-girish/MFM-models.git\n!cd  MFM-models\nimport os\nos.chdir(\"MFM-models\")  # Change directory to MFM-models\nfrom MFM_extractor import model_list, extract_from\nmodel_list()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T07:04:33.066019Z","iopub.execute_input":"2025-03-27T07:04:33.066255Z","iopub.status.idle":"2025-03-27T07:04:33.393334Z","shell.execute_reply.started":"2025-03-27T07:04:33.066234Z","shell.execute_reply":"2025-03-27T07:04:33.392240Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'MFM-models' already exists and is not an empty directory.\nAvailable models:\n1. MERT-v0\n2. MERT-v0-Public\n3. MERT-v1-95\n4. MERT-v1-330\n5. music2vec-v1-v1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T12:28:13.255076Z","iopub.execute_input":"2025-03-20T12:28:13.255414Z","iopub.status.idle":"2025-03-20T12:28:17.773726Z","shell.execute_reply.started":"2025-03-20T12:28:13.255362Z","shell.execute_reply":"2025-03-20T12:28:17.772781Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.12.1)\nCollecting nnAudio (from -r requirements.txt (line 2))\n  Downloading nnAudio-0.3.3-py3-none-any.whl.metadata (771 bytes)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->-r requirements.txt (line 1)) (1.17.1)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nnAudio->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from nnAudio->-r requirements.txt (line 2)) (1.26.4)\nRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nnAudio->-r requirements.txt (line 2)) (2.5.1+cu121)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 1)) (2.22)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->nnAudio->-r requirements.txt (line 2)) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.5->nnAudio->-r requirements.txt (line 2)) (2024.2.0)\nDownloading nnAudio-0.3.3-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nnAudio\nSuccessfully installed nnAudio-0.3.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/stable_audio_open\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/stable_audio_open.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T15:09:32.627248Z","iopub.execute_input":"2025-03-19T15:09:32.627559Z","iopub.status.idle":"2025-03-19T15:33:54.907337Z","shell.execute_reply.started":"2025-03-19T15:09:32.627537Z","shell.execute_reply":"2025-03-19T15:33:54.906417Z"}},"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 5521/5521 [24:14<00:00,  3.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/stable_audio_open.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/mustango\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/mustango.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T16:54:49.816092Z","iopub.execute_input":"2025-03-19T16:54:49.816448Z","iopub.status.idle":"2025-03-19T17:19:21.498970Z","shell.execute_reply.started":"2025-03-19T16:54:49.816417Z","shell.execute_reply":"2025-03-19T17:19:21.497737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633bb948cab44de683ece5b9757e7f53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_MERT.py:   0%|          | 0.00/5.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e63d8cdb39dc421291e9d097394088c1"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- configuration_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_MERT.py:   0%|          | 0.00/18.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7374f45fb9eb4e568ecf80fde6d2998d"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- modeling_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"name":"stdout","text":"WARNING: feature_extractor_cqt requires the libray 'nnAudio'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"572fa4e09b2448aabdfb2e54c6496480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a09fb3fa16204e61a39d3d4019bf9fe4"}},"metadata":{}},{"name":"stderr","text":"Processing audio files: 100%|██████████| 5521/5521 [23:51<00:00,  3.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/mustango.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/musicldm\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/musicldm.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T07:14:39.860844Z","iopub.execute_input":"2025-03-20T07:14:39.861212Z","iopub.status.idle":"2025-03-20T07:40:07.178976Z","shell.execute_reply.started":"2025-03-20T07:14:39.861181Z","shell.execute_reply":"2025-03-20T07:40:07.178060Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd5c159490fe41498f404e40b5eedcc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_MERT.py:   0%|          | 0.00/5.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1a782c788054c51b24febdae268ac3a"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- configuration_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_MERT.py:   0%|          | 0.00/18.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55792aae2975483aa8202aef9a83e26c"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- modeling_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"name":"stdout","text":"WARNING: feature_extractor_cqt requires the libray 'nnAudio'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d28aeeb94fe745c58a1982d063fd78a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7083af0c15e647769c14f8b524900051"}},"metadata":{}},{"name":"stderr","text":"Processing audio files: 100%|██████████| 5521/5521 [24:41<00:00,  3.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/musicldm.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/audioldm2\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/audioldm2\",\n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:19:37.902552Z","iopub.execute_input":"2025-03-20T18:19:37.902755Z","iopub.status.idle":"2025-03-20T18:19:37.911870Z","shell.execute_reply.started":"2025-03-20T18:19:37.902737Z","shell.execute_reply":"2025-03-20T18:19:37.910620Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f13d53c8e491>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m extract_from(\n\u001b[0m\u001b[1;32m      2\u001b[0m  \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m  \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/input/deepfakedatset/FakeMusicCaps/audioldm2\"\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# .wav\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/kaggle/working/Mert-v1-330/audioldm2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m  \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'extract_from' is not defined"],"ename":"NameError","evalue":"name 'extract_from' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/SunoCaps\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/SunoCaps.csv\",   \n device=\"cuda\" \n    \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T08:23:56.802208Z","iopub.execute_input":"2025-03-20T08:23:56.802520Z","iopub.status.idle":"2025-03-20T08:29:16.375764Z","shell.execute_reply.started":"2025-03-20T08:23:56.802497Z","shell.execute_reply":"2025-03-20T08:29:16.374674Z"}},"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 63/63 [05:18<00:00,  5.05s/it]","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/SunoCaps\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/MusicGen_medium\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/MusicGen_medium.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:12:33.708495Z","iopub.execute_input":"2025-03-20T09:12:33.708808Z","iopub.status.idle":"2025-03-20T09:36:52.926727Z","shell.execute_reply.started":"2025-03-20T09:12:33.708783Z","shell.execute_reply":"2025-03-20T09:36:52.925808Z"}},"outputs":[{"name":"stderr","text":"Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\nProcessing audio files: 100%|██████████| 5521/5521 [24:11<00:00,  3.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/MusicGen_medium.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/MusicCaps\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/MusicCaps.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T09:48:34.955217Z","iopub.execute_input":"2025-03-20T09:48:34.955506Z","iopub.status.idle":"2025-03-20T10:13:23.197668Z","shell.execute_reply.started":"2025-03-20T09:48:34.955485Z","shell.execute_reply":"2025-03-20T10:13:23.196808Z"}},"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 5373/5373 [24:41<00:00,  3.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/MusicCaps.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/mustango\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/mustango.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T10:18:24.767667Z","iopub.execute_input":"2025-03-20T10:18:24.767977Z","iopub.status.idle":"2025-03-20T10:44:32.316733Z","shell.execute_reply.started":"2025-03-20T10:18:24.767952Z","shell.execute_reply":"2025-03-20T10:44:32.315821Z"}},"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 5521/5521 [25:59<00:00,  3.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-330/mustango.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"extract_from(\n selection=\"4\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/MusicCaps\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-330/MusicCaps.csv\",   \n device=\"cuda\"                            \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T12:28:22.987778Z","iopub.execute_input":"2025-03-20T12:28:22.988104Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9010f2fb21e94e2ebda91281dddce284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_MERT.py:   0%|          | 0.00/5.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f0efc0f46e24738a19c5e1a74f32ed5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- configuration_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_MERT.py:   0%|          | 0.00/18.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6ffbb04ad047cf9bca7d41a68ebcfe"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/m-a-p/MERT-v1-330M:\n- modeling_MERT.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58af3fa27cf6482fa25d89ab05ed4077"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef459faf7e2b40bdb318cbd2049629cf"}},"metadata":{}},{"name":"stderr","text":"Processing audio files:  39%|███▊      | 2074/5373 [07:59<12:54,  4.26it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# Directory where the CSV files are located\ncsv_dir = \"/kaggle/working/Mert-v1-330\"  # Update with your actual folder path\n\n# List of CSV files (excluding .npy files)\ncsv_files = [\n    \"MusicCaps.csv\",\n    \"MusicGen_medium.csv\",\n    \"musicldm.csv\",\n    \"mustango.csv\",\n    \"stable_audio_open.csv\",\n    \"SunoCaps.csv\",\n    \"audioldm2.csv\"\n]\n\n# Merge all CSV files into a single DataFrame\ndf_list = []\nfor file in csv_files:\n    file_path = os.path.join(csv_dir, file)\n    df = pd.read_csv(file_path)\n    \n    # Assign labels: 1 for MusicCaps, 0 for others\n    df[\"label\"] = 1 if \"MusicCaps\" in file else 0\n    \n    df_list.append(df)\n\n# Concatenate all data\nmerged_df = pd.concat(df_list, ignore_index=True)\n\n# Save merged CSV (optional)\nmerged_df.to_csv(\"merged_dataset.csv\", index=False)\n\nprint(\"Merged dataset saved as 'merged_dataset.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:53:56.310992Z","iopub.execute_input":"2025-03-20T18:53:56.311283Z","iopub.status.idle":"2025-03-20T18:54:30.111696Z","shell.execute_reply.started":"2025-03-20T18:53:56.311263Z","shell.execute_reply":"2025-03-20T18:54:30.110910Z"}},"outputs":[{"name":"stdout","text":"Merged dataset saved as 'merged_dataset.csv'\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nprint(os.getcwd()) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T18:56:51.662984Z","iopub.execute_input":"2025-03-20T18:56:51.663362Z","iopub.status.idle":"2025-03-20T18:56:51.667804Z","shell.execute_reply.started":"2025-03-20T18:56:51.663315Z","shell.execute_reply":"2025-03-20T18:56:51.667068Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/MFM-models\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve\nimport pandas as pd\n\n# Load the merged dataset\ncsv_path = \"/kaggle/working/MFM-models/merged_dataset.csv\"\ndf = pd.read_csv(csv_path)\ndf = df.iloc[:, 1:]  # Keep all columns except the first one\n\n# Ensure the 'label' column exists\nif \"label\" not in df.columns:\n    raise ValueError(\"The dataset does not contain a 'label' column.\")\n\n# Separate features and labels\nX = df.drop(columns=[\"label\"]).values  # Drop the 'label' column\ny = df[\"label\"].values  # Use the 'label' column as the target\n\n# Split dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define CNN model\nmodel = Sequential([\n    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n    MaxPooling1D(pool_size=2),\n    Conv1D(64, kernel_size=3, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\nlogit_v0_330 = model.predict(X_train)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# Predict labels for test data\ny_scores = model.predict(X_test)  # Get raw probabilities\ny_pred = (y_scores > 0.5).astype(int)  # Convert probabilities to binary labels (0 or 1)\n\n# Generate and print classification report (rounded to 2 decimal places)\nreport = classification_report(y_test, y_pred, digits=2)\nprint(\"Classification Report:\\n\", report)\n\n# Compute and print confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n# ---------------- EER Calculation ----------------\ndef calculate_eer(y_test, y_scores):\n    fpr, tpr, thresholds = roc_curve(y_test, y_scores)  # Compute ROC curve\n    fnr = 1 - tpr  # False Negative Rate (FNR)\n\n    # Find the EER (where FPR ≈ FNR)\n    eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n    eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n\n    return eer, eer_threshold\n\neer, eer_threshold = calculate_eer(y_test, y_scores)\nprint(f\"EER: {eer:.4f} (Threshold: {eer_threshold:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-27T09:45:12.601906Z","iopub.execute_input":"2025-03-27T09:45:12.602090Z","iopub.status.idle":"2025-03-27T09:46:59.850417Z","shell.execute_reply.started":"2025-03-27T09:45:12.602072Z","shell.execute_reply":"2025-03-27T09:46:59.849450Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9792 - loss: 0.1107 - val_accuracy: 1.0000 - val_loss: 5.9847e-05\nEpoch 2/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 1.0000 - val_loss: 9.7279e-06\nEpoch 3/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 1.0000 - val_loss: 5.8120e-06\nEpoch 4/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 1.0000 - val_loss: 2.9017e-06\nEpoch 5/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 1.0000 - val_loss: 7.1844e-07\nEpoch 6/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 1.2807e-05\nEpoch 7/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 5.8509e-07\nEpoch 8/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 3.9157e-08\nEpoch 9/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 1.1634e-05\nEpoch 10/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.6606e-04 - val_accuracy: 1.0000 - val_loss: 5.1420e-08\nEpoch 11/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 7.1306e-04 - val_accuracy: 1.0000 - val_loss: 5.6140e-06\nEpoch 12/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4053e-04 - val_accuracy: 1.0000 - val_loss: 3.5046e-07\nEpoch 13/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.7777e-04 - val_accuracy: 1.0000 - val_loss: 8.6633e-07\nEpoch 14/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 2.9786e-04 - val_accuracy: 1.0000 - val_loss: 4.9543e-10\nEpoch 15/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 7.6392e-04 - val_accuracy: 1.0000 - val_loss: 6.7249e-09\nEpoch 16/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.1926e-05 - val_accuracy: 1.0000 - val_loss: 2.2487e-10\nEpoch 17/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3432e-05 - val_accuracy: 1.0000 - val_loss: 1.5307e-10\nEpoch 18/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6892e-05 - val_accuracy: 1.0000 - val_loss: 3.2631e-09\nEpoch 19/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.4359e-05 - val_accuracy: 1.0000 - val_loss: 4.5669e-11\nEpoch 20/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 3.6287e-05 - val_accuracy: 1.0000 - val_loss: 8.3693e-12\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 9.9928e-12\nTest Accuracy: 1.0000\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5566\n           1       1.00      1.00      1.00      1043\n\n    accuracy                           1.00      6609\n   macro avg       1.00      1.00      1.00      6609\nweighted avg       1.00      1.00      1.00      6609\n\nConfusion Matrix:\n [[5566    0]\n [   0 1043]]\nEER: 0.0000 (Threshold: 1.0000)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"extract_from(\n selection=\"3\",\n folder_path=\"/kaggle/input/deepfakedatset/FakeMusicCaps/SunoCaps\",    # .wav\n output_file=\"/kaggle/working/Mert-v1-95/SunoCaps.csv\",   \n device=\"cuda\"\n    \n )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T19:28:37.995461Z","iopub.execute_input":"2025-03-20T19:28:37.995934Z","iopub.status.idle":"2025-03-20T19:30:40.460655Z","shell.execute_reply.started":"2025-03-20T19:28:37.995896Z","shell.execute_reply":"2025-03-20T19:30:40.459615Z"}},"outputs":[{"name":"stderr","text":"Processing audio files: 100%|██████████| 63/63 [02:01<00:00,  1.93s/it]","output_type":"stream"},{"name":"stdout","text":"Saved all features to /kaggle/working/Mert-v1-95/SunoCaps.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve\nimport pandas as pd\n\n# Load the merged dataset\ncsv_path = \"/kaggle/working/MFM-models/merged_dataset.csv\"\ndf = pd.read_csv(csv_path)\ndf = df.iloc[:, 1:]  # Keep all columns except the first one\n\n# Ensure the 'label' column exists\nif \"label\" not in df.columns:\n    raise ValueError(\"The dataset does not contain a 'label' column.\")\n\n# Separate features and labels\nX = df.drop(columns=[\"label\"]).values  # Drop the 'label' column\ny = df[\"label\"].values  # Use the 'label' column as the target\n\n# Split dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define ANN model\nmodel = Sequential([\n    Dense(128, activation='relu', input_shape=(X.shape[1],)),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid')  # Output layer for binary classification\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n\n# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n\n# Predict labels for test data\ny_scores = model.predict(X_test)  # Get raw probabilities\ny_pred = (y_scores > 0.5).astype(int)  # Convert probabilities to binary labels (0 or 1)\n\n# Generate and print classification report (rounded to 2 decimal places)\nreport = classification_report(y_test, y_pred, digits=2)\nprint(\"Classification Report:\\n\", report)\n\n# Compute and print confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# ---------------- EER Calculation ----------------\ndef calculate_eer(y_test, y_scores):\n    fpr, tpr, thresholds = roc_curve(y_test, y_scores)  # Compute ROC curve\n    fnr = 1 - tpr  # False Negative Rate (FNR)\n\n    # Find the EER (where FPR ≈ FNR)\n    eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n    eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n\n    return eer, eer_threshold\n\neer, eer_threshold = calculate_eer(y_test, y_scores)\nprint(f\"EER: {eer:.4f} (Threshold: {eer_threshold:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T05:55:17.366112Z","iopub.execute_input":"2025-03-21T05:55:17.366509Z","iopub.status.idle":"2025-03-21T05:56:18.367042Z","shell.execute_reply.started":"2025-03-21T05:55:17.366475Z","shell.execute_reply":"2025-03-21T05:56:18.366118Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0618 - val_accuracy: 1.0000 - val_loss: 6.2030e-08\nEpoch 2/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 5.0644e-04 - val_accuracy: 1.0000 - val_loss: 5.0803e-10\nEpoch 3/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 6.1521e-04 - val_accuracy: 1.0000 - val_loss: 3.4759e-12\nEpoch 4/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.0162e-05 - val_accuracy: 1.0000 - val_loss: 2.8584e-13\nEpoch 5/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 2.3772e-16\nEpoch 6/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 1.0652e-04 - val_accuracy: 1.0000 - val_loss: 2.2282e-17\nEpoch 7/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.4301e-04 - val_accuracy: 1.0000 - val_loss: 1.1008e-19\nEpoch 8/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6433e-05 - val_accuracy: 1.0000 - val_loss: 1.3237e-21\nEpoch 9/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.3070e-06 - val_accuracy: 1.0000 - val_loss: 1.0069e-19\nEpoch 10/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3992e-07 - val_accuracy: 1.0000 - val_loss: 4.8156e-20\nEpoch 11/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2417e-08 - val_accuracy: 1.0000 - val_loss: 3.1660e-20\nEpoch 12/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9413e-04 - val_accuracy: 1.0000 - val_loss: 4.0687e-25\nEpoch 13/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 3.3928e-26\nEpoch 14/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 7.4875e-26\nEpoch 15/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 4.9981e-29\nEpoch 16/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3437e-08 - val_accuracy: 1.0000 - val_loss: 4.4877e-29\nEpoch 17/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8180e-09 - val_accuracy: 1.0000 - val_loss: 1.2914e-29\nEpoch 18/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.8940e-08 - val_accuracy: 1.0000 - val_loss: 1.0719e-29\nEpoch 19/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3446e-11 - val_accuracy: 1.0000 - val_loss: 1.0536e-29\nEpoch 20/20\n\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.4106e-11 - val_accuracy: 1.0000 - val_loss: 1.0062e-29\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 6.6551e-30\nTest Accuracy: 1.0000\n\u001b[1m207/207\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5566\n           1       1.00      1.00      1.00      1043\n\n    accuracy                           1.00      6609\n   macro avg       1.00      1.00      1.00      6609\nweighted avg       1.00      1.00      1.00      6609\n\nConfusion Matrix:\n [[5566    0]\n [   0 1043]]\nEER: 0.0000 (Threshold: 1.0000)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve\n\n# Load the merged dataset\ncsv_path = \"/kaggle/working/MFM-models/merged_dataset.csv\"\ndf = pd.read_csv(csv_path)\ndf = df.iloc[:, 1:]  # Keep all columns except the first one\n\n# Ensure the 'label' column exists\nif \"label\" not in df.columns:\n    raise ValueError(\"The dataset does not contain a 'label' column.\")\n\n# Separate features and labels\nX = df.drop(columns=[\"label\"]).values  # Drop the 'label' column\ny = df[\"label\"].values  # Use the 'label' column as the target\n\n# Split dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the SVM model\nsvm_model = SVC(kernel='rbf', probability=True, random_state=42)  # Using RBF kernel\nsvm_model.fit(X_train, y_train)\n\n# Predict labels for test data\ny_scores = svm_model.predict_proba(X_test)[:, 1]  # Get probability scores for class 1\ny_pred = svm_model.predict(X_test)  # Get binary predictions\n\n# Generate and print classification report\nreport = classification_report(y_test, y_pred, digits=2)\nprint(\"Classification Report:\\n\", report)\n\n# Compute and print confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# ---------------- EER Calculation ----------------\ndef calculate_eer(y_test, y_scores):\n    fpr, tpr, thresholds = roc_curve(y_test, y_scores)  # Compute ROC curve\n    fnr = 1 - tpr  # False Negative Rate (FNR)\n\n    # Find the EER (where FPR ≈ FNR)\n    eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n    eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n\n    return eer, eer_threshold\n\neer, eer_threshold = calculate_eer(y_test, y_scores)\nprint(f\"EER: {eer:.4f} (Threshold: {eer_threshold:.4f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T07:54:35.233650Z","iopub.execute_input":"2025-03-21T07:54:35.233865Z","iopub.status.idle":"2025-03-21T07:55:03.899816Z","shell.execute_reply.started":"2025-03-21T07:54:35.233845Z","shell.execute_reply":"2025-03-21T07:55:03.898789Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5566\n           1       1.00      1.00      1.00      1043\n\n    accuracy                           1.00      6609\n   macro avg       1.00      1.00      1.00      6609\nweighted avg       1.00      1.00      1.00      6609\n\nConfusion Matrix:\n [[5566    0]\n [   0 1043]]\nEER: 0.0000 (Threshold: 1.0000)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}